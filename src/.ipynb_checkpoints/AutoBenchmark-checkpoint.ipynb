{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Distributions\n",
    "using CUDA\n",
    "using BenchmarkTools, Base.Threads\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decide_old (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Kernels\n",
    "\n",
    "#Method 1 of Vd\n",
    "#A += (1-ϕ)* Vd0\n",
    "function sumdef1(sumdef,Vd,Vd0,V0,ϕ,β,P)\n",
    "    #sumdef = CUDA.zeros(Ny)\n",
    "    A = ϕ* V0[:,1]\n",
    "    A += (1-ϕ)* Vd0\n",
    "    A.= ϕ.* V0[:,1] .+ (1-ϕ).* Vd0\n",
    "    temp = P\n",
    "    temp .*= CUDA.transpose(A)\n",
    "    temp .*= β\n",
    "    #temp = β* P .* CUDA.transpose(A)\n",
    "    sumdef += reduce(+, temp, dims=2) #This gives Vd\n",
    "    #Then do a value transport to Vd\n",
    "    Vd = sumdef\n",
    "end\n",
    "\n",
    "#line 7.1 Intitializing U((1-τ)iy) to each Vd[iy]\n",
    "function def_init(sumdef,τ,Y,α)\n",
    "    iy = threadIdx().x\n",
    "    stride = blockDim().x\n",
    "    for i = iy:stride:length(sumdef)\n",
    "        sumdef[i] = CUDA.pow(exp((1-τ)*Y[i]),(1-α))/(1-α)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#adding expected value to sumdef\n",
    "function def_add(matrix, P, β, V0, Vd0, ϕ, Ny)\n",
    "    y = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (iy <= Ny && y <= Ny)\n",
    "        matrix[iy,y] = β* P[iy,y]* (ϕ* V0[y,1] + (1-ϕ)* Vd0[y])\n",
    "        #Note memory transfer of matrices of P and Vd0 are not optimal\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#Method 2 of Vd\n",
    "function sumdef2(sumdef) #Calculate sumdef in a kernel\n",
    "    @cuda threads=threadcount blocks=blockcount def_init(sumdef,τ,Y,α)\n",
    "    temp = CUDA.zeros(Ny,Ny)\n",
    "    blockcount = (ceil(Int,Ny/10),ceil(Int,Ny/10))\n",
    "    @cuda threads=threadcount blocks=blockcount def_add(temp, P, β, V0, Vd0, ϕ, Ny)\n",
    "    sumdef += reduce(+, temp, dims=2)\n",
    "end\n",
    "\n",
    "#@benchmark sumdef1(sumdef) #240.6 μs\n",
    "#@benchmark sumdef2(sumdef)\n",
    "#----\n",
    "\n",
    "#Calculate Cost Matrix C\n",
    "function vr_C(Ny,Nb,Y,B,Price0,P,C)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            C[iy,ib,b] = -Price0[iy,b]*B[b] + CUDA.exp(Y[iy]) + B[ib]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#map C -> U(C), then add β*sumret\n",
    "function vr_C2(Ny,Nb,Vr,V0,Y,B,Price0,P,C,C2,sumret,α)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            if C[iy,ib,b] > 0\n",
    "                c = C[iy,ib,b]\n",
    "                C2[iy,ib,b] = CUDA.pow(c,(1-α)) / (1-α) + B[ib] - Price0[iy,b]*B[b] #Note CUDA.pow only support certain types, need to cast constant to Float32 instead of Float64\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#----\n",
    "#Calcuate sumret[iy,ib,b]\n",
    "function vr_sumret(Ny,Nb,V0,P,sumret)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            sumret[iy,ib,b] = 0\n",
    "            for y in 1:Ny\n",
    "                sumret[iy,ib,b] += P[iy,b]*V0[y,b]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "#---\n",
    "#write into decision function\n",
    "function decide(Ny,Nb,Vd,Vr,V,decision)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        if (Vd[iy] < Vr[iy,ib])\n",
    "            V[iy,ib] = Vr[iy,ib]\n",
    "            decision[iy,ib] = 0\n",
    "        else\n",
    "            V[iy,ib] = Vd[iy]\n",
    "            decision[iy,ib] = 1\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function prob_calc(Ny,Nb,prob,P,decision)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        #prob[iy,ib] = P[iy,:]'decision[:,ib]\n",
    "        for y in Ny\n",
    "            prob[iy,ib] += P[iy,y]*decision[y,ib]\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "Price_calc(x, rstar) = (1-x) / (1+rstar)\n",
    "#@benchmark Price = Price_calc.(prob, rstar)\n",
    "\n",
    "\n",
    "#line 7.1 Intitializing U((1-τ)iy) to each Vd[iy] #BATCH UPDATE\n",
    "function def_init_old(sumdef,τ,Y,α)\n",
    "    iy = threadIdx().x\n",
    "    stride = blockDim().x\n",
    "    for i = iy:stride:length(sumdef)\n",
    "        sumdef[i] = exp((1-τ)*Y[i])/(1-α)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#line 7.2 adding second expected part to calcualte Vd[iy]\n",
    "function def_add_old(matrix, P, β, V0, Vd0, ϕ, Ny)\n",
    "    y = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (iy <= Ny && y <= Ny)\n",
    "        matrix[iy,y] = β* P[iy,y]* (ϕ* V0[y,1] + (1-ϕ)* Vd0[y])\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function vr_old(Nb,Ny,α,β,τ,Vr,V0,Y,B,Price0,P)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        Max = -Inf\n",
    "        for b in 1:Nb\n",
    "            c = Float32(CUDA.exp(Y[iy]) + B[ib] - Price0[iy,b]*B[b])\n",
    "            if c > 0 #If consumption positive, calculate value of return\n",
    "                sumret = 0\n",
    "                for y in 1:Ny\n",
    "                    sumret += V0[y,b]*P[iy,y]\n",
    "                end\n",
    "                Max = CUDA.max(Max, CUDA.pow(c,(1-α))/(1-α) + β * sumret)\n",
    "            end\n",
    "        end\n",
    "        Vr[iy,ib] = Max\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "#line 9-14 debt price update\n",
    "function Decide_old(Nb,Ny,Vd,Vr,V,decision,decision0,prob,P,Price,rstar)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        if (Vd[iy] < Vr[iy,ib])\n",
    "            V[iy,ib] = Vr[iy,ib]\n",
    "            decision[iy,ib] = 0\n",
    "        else\n",
    "            V[iy,ib] = Vd[iy]\n",
    "            decision[iy,ib] = 1\n",
    "        end\n",
    "\n",
    "        for y in 1:Ny\n",
    "            prob[iy,ib] += P[iy,y] * decision[y,ib]\n",
    "        end\n",
    "\n",
    "        Price[iy,ib] = (1-prob[iy,ib]) / (1+rstar)\n",
    "\n",
    "    end\n",
    "    return\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bench_old_version (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Benchmark on old implementation\n",
    "#Using @benchmark\n",
    "#add grid_space element N to test on N*N endowment*bond matrix\n",
    "function bench_old_version()\n",
    "\n",
    "    Grid_space = [100] #[50 100 150 200 300 400]# 450 500 550 600]\n",
    "    global BenchResultsMedian = zeros(10,length(Grid_space))\n",
    "\n",
    "    global iter=1\n",
    "\n",
    "    for i in Grid_space\n",
    "        println(\"round $iter\")\n",
    "        \n",
    "        #Initialize varaibles\n",
    "        Ny = i\n",
    "        Nb = i\n",
    "        maxInd = Ny * Nb #total grid points\n",
    "        rstar = Float32(0.017) #r* used in price calculation\n",
    "        α = Float32(0.5) #α used in utility function\n",
    "\n",
    "        #lower bound and upper bound for bond initialization\n",
    "        lbd = -1\n",
    "        ubd = 0\n",
    "\n",
    "        #β,ϕ,τ used as in part 4 of original paper\n",
    "        β = Float32(0.953)\n",
    "        ϕ = Float32(0.282)\n",
    "        τ = Float32(0.5)\n",
    "\n",
    "        δ = Float32(0.8) #weighting average of new and old matrixs\n",
    "\n",
    "        #ρ,σ For tauchen method\n",
    "        ρ = Float32(0.9)\n",
    "        σ = Float32(0.025)\n",
    "\n",
    "\n",
    "        #Initializing Bond matrix\n",
    "        minB = lbd\n",
    "        maxB = ubd\n",
    "        step = (maxB-minB) / (Nb-1)\n",
    "        B = CuArray(minB:step:maxB) #Bond\n",
    "\n",
    "        #Intitializing Endowment matrix\n",
    "        σ_z = sqrt((σ^2)/(1-ρ^2))\n",
    "        Step = 10*σ_z/(Ny-1)\n",
    "        Y = CuArray(-5*σ_z:Step:5*σ_z) #Endowment\n",
    "\n",
    "        Pcpu = zeros(Ny,Ny)  #Conditional probability matrix\n",
    "        V = CUDA.fill(1/((1-β)*(1-α)), Ny, Nb) #Value\n",
    "        Price = CUDA.fill(1/(1+rstar), Ny, Nb) #Debt price\n",
    "        Vr = CUDA.zeros(Ny, Nb) #Value of good standing\n",
    "        Vd = CUDA.zeros(Ny) #Value of default\n",
    "        C = CUDA.zeros(Ny,Nb,Nb)\n",
    "        VR = CUDA.zeros(Ny,Nb,Nb)\n",
    "        sumret = CUDA.zeros(Ny,Nb,Nb)\n",
    "        V0 = CUDA.deepcopy(V)\n",
    "        Vd0 = CUDA.deepcopy(Vd)\n",
    "        Price0 = CUDA.deepcopy(Price)\n",
    "        prob = CUDA.zeros(Ny,Nb)\n",
    "        decision = CUDA.ones(Ny,Nb)\n",
    "        decision0 = CUDA.deepcopy(decision)\n",
    "        sumdef = CUDA.zeros(Ny)\n",
    "        C2 = CUDA.zeros(Ny,Nb,Nb)\n",
    "        global vr\n",
    "        elem = 1\n",
    "        global temp = CUDA.zeros(Ny,Ny)\n",
    "        tauchen(ρ, σ, Ny, Pcpu)\n",
    "        P = CuArray(Pcpu)\n",
    "\n",
    "        global threadcount = (16,16) #set up defualt thread numbers per block\n",
    "        global blockcount = (ceil(Int,Ny/10),ceil(Int,Ny/10))\n",
    "\n",
    "        println(\"begin benchmark\")\n",
    "    \n",
    "        \n",
    "        #Part 1, get total time for value of default calculation, t0+t1+t2+t3\n",
    "        t0 = @benchmark @cuda threads=50 def_init_old(sumdef,τ,Y,α)\n",
    "        BenchResultsMedian[elem,iter] = time(median(t0))\n",
    "        elem += 1\n",
    "        \n",
    "        t1 = @benchmark @cuda threads=threadcount blocks=blockcount def_add_old(temp, P, β, V0, Vd0, ϕ, Ny)\n",
    "        BenchResultsMedian[elem,iter] = time(median(t1))\n",
    "        elem += 1\n",
    "        \n",
    "        t2 = @benchmark temp2 = sum(temp,dims=2)\n",
    "        global temp2 = sum(temp,dims=2)\n",
    "        t3 = @benchmark sumdef2 = sumdef + temp2\n",
    "        BenchResultsMedian[elem,iter] = time(median(t0)) + time(median(t1)) + time(median(t2)) + time(median(t3))\n",
    "        elem += 1\n",
    "\n",
    "        #Part 2, get total time for value of repayment calculation\n",
    "        t = @benchmark @cuda threads=threadcount blocks=blockcount vr_old(Nb,Ny,α,β,τ,Vr,V0,Y,B,Price0,P)\n",
    "        BenchResultsMedian[elem,iter] = time(median(t))\n",
    "        elem += 1\n",
    "        \n",
    "        #Part 3, get total time for decision calculation\n",
    "        t = @benchmark @cuda threads=threadcount blocks=blockcount Decide_old(Nb,Ny,Vd,Vr,V,decision,decision0,prob,P,Price,rstar)\n",
    "        BenchResultsMedian[elem,iter] = time(median(t))\n",
    "        elem += 1\n",
    "\n",
    "        println(\"iter $iter over\")\n",
    "        iter+=1\n",
    "        display(BenchResultsMedian)\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 1\n",
      "begin benchmark\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: temp not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: temp not defined",
      "",
      "Stacktrace:",
      " [1] macro expansion at C:\\Users\\dengmingzhuo\\.julia\\packages\\CUDA\\5t6R9\\src\\compiler\\execution.jl:55 [inlined]",
      " [2] ##core#371() at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:371",
      " [3] ##sample#372(::BenchmarkTools.Parameters) at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:377",
      " [4] _run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#370\")}, ::BenchmarkTools.Parameters; verbose::Bool, pad::String, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{4,Symbol},NamedTuple{(:samples, :evals, :gctrial, :gcsample),Tuple{Int64,Int64,Bool,Bool}}}) at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:405",
      " [5] (::Base.var\"#inner#2\"{Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}},typeof(BenchmarkTools._run),Tuple{BenchmarkTools.Benchmark{Symbol(\"##benchmark#370\")},BenchmarkTools.Parameters}})() at .\\essentials.jl:715",
      " [6] #invokelatest#1 at .\\essentials.jl:716 [inlined]",
      " [7] #run_result#37 at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:32 [inlined]",
      " [8] run(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#370\")}, ::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, kwargs::Base.Iterators.Pairs{Symbol,Integer,NTuple{5,Symbol},NamedTuple{(:verbose, :samples, :evals, :gctrial, :gcsample),Tuple{Bool,Int64,Int64,Bool,Bool}}}) at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:94",
      " [9] #warmup#45 at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:141 [inlined]",
      " [10] warmup(::BenchmarkTools.Benchmark{Symbol(\"##benchmark#370\")}) at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:141",
      " [11] macro expansion at C:\\Users\\dengmingzhuo\\.julia\\packages\\BenchmarkTools\\eCEpo\\src\\execution.jl:287 [inlined]",
      " [12] bench_old_version() at .\\In[15]:81",
      " [13] top-level scope at In[16]:1"
     ]
    }
   ],
   "source": [
    "bench_old_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const plt = PyPlot;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

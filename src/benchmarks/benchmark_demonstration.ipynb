{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three blocks set up the library, kernels&functions, and the data matrices\n",
    "Then choose kernel to benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Distributions\n",
    "using CUDA\n",
    "using BenchmarkTools, Base.Threads\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tauchen (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Kernels\n",
    "\n",
    "#Method 1 of Vd\n",
    "#A += (1-ϕ)* Vd0\n",
    "function sumdef1(sumdef,Vd,Vd0,V0,ϕ,β,P)\n",
    "    #sumdef = CUDA.zeros(Ny)\n",
    "    A = ϕ* V0[:,1]\n",
    "    A += (1-ϕ)* Vd0\n",
    "    A.= ϕ.* V0[:,1] .+ (1-ϕ).* Vd0\n",
    "    temp = P\n",
    "    temp .*= CUDA.transpose(A)\n",
    "    temp .*= β\n",
    "    #temp = β* P .* CUDA.transpose(A)\n",
    "    sumdef += reduce(+, temp, dims=2) #This gives Vd\n",
    "    #Then do a value transport to Vd\n",
    "    Vd = sumdef\n",
    "end\n",
    "\n",
    "#line 7.1 Intitializing U((1-τ)iy) to each Vd[iy]\n",
    "function def_init(sumdef,τ,Y,α)\n",
    "    iy = threadIdx().x\n",
    "    stride = blockDim().x\n",
    "    for i = iy:stride:length(sumdef)\n",
    "        sumdef[i] = CUDA.pow(exp((1-τ)*Y[i]),(1-α))/(1-α)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#adding expected value to sumdef\n",
    "function def_add(matrix, P, β, V0, Vd0, ϕ, Ny)\n",
    "    y = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (iy <= Ny && y <= Ny)\n",
    "        matrix[iy,y] = β* P[iy,y]* (ϕ* V0[y,1] + (1-ϕ)* Vd0[y])\n",
    "        #Note memory transfer of matrices of P and Vd0 are not optimal\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#Method 2 of Vd\n",
    "function sumdef2(sumdef) #Calculate sumdef in a kernel\n",
    "    @cuda threads=threadcount blocks=blockcount def_init(sumdef,τ,Y,α)\n",
    "    temp = CUDA.zeros(Ny,Ny)\n",
    "    blockcount = (ceil(Int,Ny/10),ceil(Int,Ny/10))\n",
    "    @cuda threads=threadcount blocks=blockcount def_add(temp, P, β, V0, Vd0, ϕ, Ny)\n",
    "    sumdef += reduce(+, temp, dims=2)\n",
    "end\n",
    "\n",
    "#@benchmark sumdef1(sumdef) #240.6 μs\n",
    "#@benchmark sumdef2(sumdef)\n",
    "#----\n",
    "\n",
    "#Calculate Cost Matrix C\n",
    "function vr_C(Ny,Nb,Y,B,Price0,P,C)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            C[iy,ib,b] = -Price0[iy,b]*B[b] + CUDA.exp(Y[iy]) + B[ib]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#map C -> U(C), then add β*sumret\n",
    "function vr_C2(Ny,Nb,Vr,V0,Y,B,Price0,P,C,C2,sumret,α)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            if C[iy,ib,b] > 0\n",
    "                c = C[iy,ib,b]\n",
    "                C2[iy,ib,b] = CUDA.pow(c,(1-α)) / (1-α) + B[ib] - Price0[iy,b]*B[b] #Note CUDA.pow only support certain types, need to cast constant to Float32 instead of Float64\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#----\n",
    "#Calcuate sumret[iy,ib,b]\n",
    "function vr_sumret(Ny,Nb,V0,P,sumret)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        for b in 1:Nb\n",
    "            sumret[iy,ib,b] = 0\n",
    "            for y in 1:Ny\n",
    "                sumret[iy,ib,b] += P[iy,b]*V0[y,b]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "#---\n",
    "#write into decision function\n",
    "function decide(Ny,Nb,Vd,Vr,V,decision)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        if (Vd[iy] < Vr[iy,ib])\n",
    "            V[iy,ib] = Vr[iy,ib]\n",
    "            decision[iy,ib] = 0\n",
    "        else\n",
    "            V[iy,ib] = Vd[iy]\n",
    "            decision[iy,ib] = 1\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function prob_calc(Ny,Nb,prob,P,decision)\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "        #prob[iy,ib] = P[iy,:]'decision[:,ib]\n",
    "        for y in Ny\n",
    "            prob[iy,ib] += P[iy,y]*decision[y,ib]\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "Price_calc(x, rstar) = (1-x) / (1+rstar)\n",
    "#@benchmark Price = Price_calc.(prob, rstar)\n",
    "\n",
    "\n",
    "#line 7.1 Intitializing U((1-τ)iy) to each Vd[iy] #BATCH UPDATE\n",
    "function def_init_old(sumdef,τ,Y,α)\n",
    "    iy = threadIdx().x\n",
    "    stride = blockDim().x\n",
    "    for i = iy:stride:length(sumdef)\n",
    "        sumdef[i] = exp((1-τ)*Y[i])/(1-α)\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "#line 7.2 adding second expected part to calcualte Vd[iy]\n",
    "function def_add_old(matrix, P, β, V0, Vd0, ϕ, Ny)\n",
    "    y = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (iy <= Ny && y <= Ny)\n",
    "        matrix[iy,y] = β* P[iy,y]* (ϕ* V0[y,1] + (1-ϕ)* Vd0[y])\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "function vr_old(Nb,Ny,α,β,τ,Vr,V0,Y,B,Price0,P)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        Max = -Inf\n",
    "        for b in 1:Nb\n",
    "            c = Float32(CUDA.exp(Y[iy]) + B[ib] - Price0[iy,b]*B[b])\n",
    "            if c > 0 #If consumption positive, calculate value of return\n",
    "                sumret = 0\n",
    "                for y in 1:Ny\n",
    "                    sumret += V0[y,b]*P[iy,y]\n",
    "                end\n",
    "                Max = CUDA.max(Max, CUDA.pow(c,(1-α))/(1-α) + β * sumret)\n",
    "            end\n",
    "        end\n",
    "        Vr[iy,ib] = Max\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "#line 9-14 debt price update\n",
    "function Decide_old(Nb,Ny,Vd,Vr,V,decision,decision0,prob,P,Price,rstar)\n",
    "\n",
    "    ib = (blockIdx().x-1)*blockDim().x + threadIdx().x\n",
    "    iy = (blockIdx().y-1)*blockDim().y + threadIdx().y\n",
    "\n",
    "    if (ib <= Nb && iy <= Ny)\n",
    "\n",
    "        if (Vd[iy] < Vr[iy,ib])\n",
    "            V[iy,ib] = Vr[iy,ib]\n",
    "            decision[iy,ib] = 0\n",
    "        else\n",
    "            V[iy,ib] = Vd[iy]\n",
    "            decision[iy,ib] = 1\n",
    "        end\n",
    "\n",
    "        for y in 1:Ny\n",
    "            prob[iy,ib] += P[iy,y] * decision[y,ib]\n",
    "        end\n",
    "\n",
    "        Price[iy,ib] = (1-prob[iy,ib]) / (1+rstar)\n",
    "\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "function tauchen(ρ, σ, Ny, P)\n",
    "    #Create equally spaced pts to fill into Z\n",
    "    σ_z = sqrt((σ^2)/(1-ρ^2))\n",
    "    Step = 10*σ_z/(Ny-1)\n",
    "    Z = -5*σ_z:Step:5*σ_z\n",
    "\n",
    "    #Fill in entries of 1~ny, ny*(ny-1)~ny^2\n",
    "    for z in 1:Ny\n",
    "        P[z,1] = cdf(Normal(), (Z[1]-ρ*Z[z] + Step/2)/σ)\n",
    "        P[z,Ny] = 1 - cdf(Normal(),(Z[Ny] - ρ*Z[z] - Step/2)/σ)\n",
    "    end\n",
    "\n",
    "    #Fill in the middle part\n",
    "    for z in 1:Ny\n",
    "        for iz in 2:(Ny-1)\n",
    "            P[z,iz] = cdf(Normal(), (Z[iz]-ρ*Z[z]+Step/2)/σ) - cdf(Normal(), (Z[iz]-ρ*Z[z]-Step/2)/σ)\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Ny and Nb below to change matrix to size Ny * Nb\n",
    "To demonstrate I use 300 * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `haskey(::TargetIterator, name::String)` is deprecated, use `Target(; name = name) !== nothing` instead.\n",
      "│   caller = llvm_compat(::VersionNumber) at compatibility.jl:176\n",
      "└ @ CUDA C:\\Users\\dengmingzhuo\\.julia\\packages\\CUDA\\5t6R9\\deps\\compatibility.jl:176\n",
      "┌ Warning: `Target(triple::String)` is deprecated, use `Target(; triple = triple)` instead.\n",
      "│   caller = ip:0x0\n",
      "└ @ Core :-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting parameters\n",
    "Ny = 300 #grid number of endowment\n",
    "Nb = 300 #grid number of bond\n",
    "maxInd = Ny * Nb #total grid points\n",
    "rstar = 0.017 #r* used in price calculation\n",
    "α = Float32(0.5) #α used in utility function\n",
    "\n",
    "#lower bound and upper bound for bond initialization\n",
    "lbd = -1\n",
    "ubd = 0\n",
    "\n",
    "#β,ϕ,τ used as in part 4 of original paper\n",
    "β = 0.953\n",
    "ϕ = 0.282\n",
    "τ = 0.5\n",
    "\n",
    "δ = 0.8 #weighting average of new and old matrixs\n",
    "\n",
    "#ρ,σ For tauchen method\n",
    "ρ = 0.9\n",
    "σ = 0.025\n",
    "\n",
    "\n",
    "#Initializing Bond matrix\n",
    "minB = lbd\n",
    "maxB = ubd\n",
    "step = (maxB-minB) / (Nb-1)\n",
    "B = CuArray(minB:step:maxB) #Bond\n",
    "\n",
    "#Intitializing Endowment matrix\n",
    "σ_z = sqrt((σ^2)/(1-ρ^2))\n",
    "Step = 10*σ_z/(Ny-1)\n",
    "Y = CuArray(-5*σ_z:Step:5*σ_z) #Endowment\n",
    "\n",
    "Pcpu = zeros(Ny,Ny)  #Conditional probability matrix\n",
    "V = CUDA.fill(1/((1-β)*(1-α)), Ny, Nb) #Value\n",
    "Price = CUDA.fill(1/(1+rstar), Ny, Nb) #Debt price\n",
    "Vr = CUDA.zeros(Ny, Nb) #Value of good standing\n",
    "Vd = CUDA.zeros(Ny) #Value of default\n",
    "decision = CUDA.ones(Ny, Nb) #Decision matrix\n",
    "C = CUDA.zeros(Ny,Nb,Nb)\n",
    "VR = CUDA.zeros(Ny,Nb,Nb)\n",
    "sumret = CUDA.zeros(Ny,Nb,Nb)\n",
    "global temp = CUDA.zeros(Ny,Ny)\n",
    "\n",
    "#U(x) = x^(1-α) / (1-α) #Utility function, change this into a function\n",
    "function U(x)\n",
    "    if x >= 0\n",
    "        return x^(1-α) / (1-α) #Utility function7\n",
    "    end\n",
    "    return 0\n",
    "end\n",
    "function U2(x)\n",
    "    return (x>0) * (x+0im)^(1-α) / (1-α)\n",
    "end\n",
    "#U2.(C)\n",
    "\n",
    "#Initialize Conditional Probability matrix\n",
    "tauchen(ρ, σ, Ny, Pcpu)\n",
    "P=CuArray(Pcpu)\n",
    "\n",
    "\n",
    "err = 2000 #error\n",
    "tol = 1e-3 #error toleration\n",
    "iter = 0\n",
    "maxIter = 500 #Maximum interation\n",
    "\n",
    "V0 = CUDA.deepcopy(V)\n",
    "Vd0 = CUDA.deepcopy(Vd)\n",
    "Price0 = CUDA.deepcopy(Price)\n",
    "prob = CUDA.zeros(Ny,Nb)\n",
    "decision = CUDA.ones(Ny,Nb)\n",
    "decision0 = CUDA.deepcopy(decision)\n",
    "C = CUDA.zeros(Ny,Nb,Nb)\n",
    "#We set up C2, sumret and sumdef in device memory\n",
    "sumret = CUDA.zeros(Ny,Nb,Nb)\n",
    "sumdef = CUDA.zeros(Ny)\n",
    "C2 = CUDA.zeros(Ny,Nb,Nb)\n",
    "\n",
    "threadcount = (16,16) #set up defualt thread numbers per block\n",
    "blockcount = (ceil(Int,Ny/10),ceil(Int,Ny/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.19 KiB\n",
       "  allocs estimate:  106\n",
       "  --------------\n",
       "  minimum time:     12.200 μs (0.00% GC)\n",
       "  median time:      13.000 μs (0.00% GC)\n",
       "  mean time:        632.538 ms (0.00% GC)\n",
       "  maximum time:     8.223 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          13\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using Benchmark on old Value of Repayment calculation, matrix size 300*300\n",
    "@benchmark @cuda threads=threadcount blocks=blockcount vr_old(Nb,Ny,α,β,τ,Vr,V0,Y,B,Price0,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  7.88 KiB\n",
       "  allocs estimate:  189\n",
       "  --------------\n",
       "  minimum time:     72.000 μs (0.00% GC)\n",
       "  median time:      75.900 μs (0.00% GC)\n",
       "  mean time:        85.386 μs (1.01% GC)\n",
       "  maximum time:     12.451 ms (69.02% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Benchmark on new Value of Repayment, adding the time of three steps together\n",
    "t0 = @benchmark @cuda threads=threadcount blocks=blockcount vr_sumret(Ny,Nb,V0,P,sumret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.95 KiB\n",
       "  allocs estimate:  61\n",
       "  --------------\n",
       "  minimum time:     14.801 μs (0.00% GC)\n",
       "  median time:      18.201 μs (0.00% GC)\n",
       "  mean time:        702.941 ms (0.00% GC)\n",
       "  maximum time:     11.247 s (0.00% GC)\n",
       "  --------------\n",
       "  samples:          16\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = @benchmark sumret .*= β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  8.02 KiB\n",
       "  allocs estimate:  198\n",
       "  --------------\n",
       "  minimum time:     69.200 μs (0.00% GC)\n",
       "  median time:      422.500 μs (0.00% GC)\n",
       "  mean time:        8.319 ms (0.00% GC)\n",
       "  maximum time:     158.544 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          609\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = @benchmark reduce(max,vr,dims=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time(median(t0)) + time(median(t1)) + time(median(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using @time to get the median time\n",
    "counter = 30\n",
    "t=[]\n",
    "    for i in 1:counter\n",
    "        time = @timed @cuda threads=threadcount blocks=blockcount vr_old(Nb,Ny,α,β,τ,Vr,V0,Y,B,Price0,P)\n",
    "        push!(t, time[2])\n",
    "    end\n",
    "median(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

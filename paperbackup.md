**Reconnecting…**

#### Download

- [
  Source](https://www.overleaf.com/project/5fab5f9c75e92477fd132069/download/zip)
- [
  PDF](https://www.overleaf.com/download/project/5fab5f9c75e92477fd132069/build/175e9d46afc-72d4cc0efa6b92b3/output/output.pdf?compileGroup=priority&clsiserverid=clsi-pre-emp-n1-b-8211&popupDownload=true)

Actions[  Copy Project](https://www.overleaf.com/project/5fab5f9c75e92477fd132069)[  Word Count](https://www.overleaf.com/project/5fab5f9c75e92477fd132069)

#### Sync

  Dropbox  Git  GitHub

#### Settings

CompilerpdfLaTeXLaTeXXeLaTeXLuaLaTeX

TeX Live version2020201920182017 (Legacy)2016 (Overleaf v1) (Legacy)2016 (ShareLaTeX) (Legacy)2015 (Legacy)2014 (Legacy)

Main documentpublication1/publication1.texpublication2/publication2.texcv.texforeword(todelete).texms.tex

Spell checkOffEnglishEnglish (American)English (British)English (Canadian)AfrikaansArabicGalicianBasqueBretonBulgarianCatalanCroatianCzechDanishDutchEsperantoEstonianFaroeseFrenchGermanGreekIndonesianIrishItalianKazakhKurdishLatvianLithuanianNdebeleNorthern SothoNorwegianPersianPolishPortuguese (Brazilian)Portuguese (European)PunjabiRomanianRussianSlovakSlovenianSouthern SothoSpanishSwedishTagalogTsongaTswanaUpper SorbianWelshXhosa

Auto-completeOnOff

Auto-close BracketsOnOff

Code checkOnOff

Editor themeambiancechaoschromecloudsclouds midnightcobaltcrimson editordawndraculadreamweavereclipsegithubgobgruvboxidle fingersiplastickatzenmilchkr themekuroirmerbivoremerbivore softmono industrialmonokainord darkoverleafpastel on darksolarized darksolarized lightsqlserverterminaltextmatetomorrowtomorrow nighttomorrow night bluetomorrow night brighttomorrow night eightiestwilightvibrant inkxcode

Overall themeDefaultLight

KeybindingsNoneVimEmacs

Font Size10px11px12px13px14px16px18px20px22px24px

Font FamilyMonacoLucida

Line HeightCompactNormalWide

PDF ViewerBuilt-InNative

#### Help

-   Show Hotkeys
- [  Documentation](https://www.overleaf.com/learn)
-   Contact Us



**Parallel Default**

Editor mode.SourceRich Text

417

418

419

420

421

422

423

424

425

426

427

428

​    In Guerron's CUDA implementation, the Thrust 

  code using operator provides an efficient and 

  intuitive transition of CPU code to GPU code. 

  This paper improves upon the design. First we 

  inspect the implicit extra computation cost in 

  the Thrust design: large variation of execution 

  time among the threads may impact overall 

  performance. During every round of computation 

  in the threads, the quicker threads will wait 

  for the slower threads to finish calculation, 

  requiring additional synchronization time for 

  each round of computation. In addition, ssame 

  data will be calculated, and freshly stored on 

  device for each thread, requiring additional 

  device space and computation power. \\

​    

​    A simple and efficient fix is to divide the 

  value repayment calculation into components. 

  Each component is computed in a small kernel, 

  thus the waiting time is reduced in 

  synchronization. The code for the three kernels 

  are attached in the appendix and GitHub.\\

​    

​    Since the \texttt{'} operator is not currently 

  supported in CUDA kernel, the calculation of 

  sum of return requires one additional for-loop, 

  a total of four for-loops. Two for-loops are 

  reduced by the two-dimensional thread 

  assignment, and two loops are contained in 

  kernel calculations. This reduces the 

  complexity from $O(n^4)$ to roughly $O(n^2)$, a 

  big speed up to about twenty-five hundred times 

  faster even on a rough $50\times50$ grid (the 

  maximum speed up is bounded by the GPU design). 

  In the bench-marking section, the two-for-loop 

  design will be shown to yield satisfying 

  result.\\

 



[Recompile](https://www.overleaf.com/project/5fab5f9c75e92477fd132069)

[**38**](https://www.overleaf.com/project/5fab5f9c75e92477fd132069)





×

### Out of sync

Sorry, this file has gone out of sync and we need to do a full refresh.
[Please see this help guide for more information](https://www.overleaf.com/learn/Kb/Editor_out_of_sync_problems)

Hide Local File Contents

\documentclass[12pt, a4paper, unicode]{report} \usepackage[utf8]{inputenc} \usepackage{ifthen}     %% If then else \usepackage{verbatim}   %% For printing latex code \usepackage{lipsum}     %% For lorem ipsum sample text \usepackage{etoolbox}   %% Bibliography chapter to section \usepackage{multibbl}   %% Multiple bibliographies \usepackage{epigraph}   %% Adding text to part pages \usepackage{epipart}    %% Custom code to add epigraph to part pages \usepackage{titletoc}   %% Multiple tables of content \usepackage{graphicx}   %% Sample images \usepackage{longtable}  %% Tables spanning more pages \usepackage{ragged2e}   %% Alignment of quotes \usepackage[svgnames]{xcolor} %% PACKAGES USED ONLY IN FOREWORD PAGE (SAFE TO DELETE) \usepackage{setspace}   %% Changing line height in foreword (delete this)  \usepackage{xcolor}     %% Changing the background color of foreword (delete this) \usepackage{afterpage}  %% Changing the color back (delete this) \usepackage{listings} \usepackage[hypertexnames=false]{hyperref} \usepackage[all]{hypcap}%% Hyperlinks to the beginning of the figure % Epigraph on the full textwidth justified to the left % We use the epigraph in custom epipart.sty to display toc on \part page \setlength{\epigraphwidth}{\textwidth} \renewcommand{\epigraphflush}{flushleft} \newcommand{\smalltoc}[4]{    % Custom command for easy creation of the partial table of content    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % First argument is the identifier of the toc    % Second argument is starting depth of the toc    % Third argument is depth of the toc    % Fourth argument is optional section* name    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % Contents of this toc is stopped automatically when     % the next startcontent with the same name is issued.    % To alter this, you can use \stopcontents[name] to     % manually set what needs to be in your toc.    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \vspace{1pc}    \ifthenelse{\equal{#4}{}}{}{\section*{#4}}    \hrule\vspace{1pc}    \startcontents[#1]    \printcontents[#1]{}{#2}[#3]{}    \vspace{1pc}    \hrule    \vspace{1pc} } % Redefining the default behavior of Chapters in report  % to get rid of the "Chapter" line before chapter title % Comment this code if you do not like it    \makeatletter    \def\@makechapterhead#1{%      \vspace*{50\p@}%      {\parindent \z@ \raggedright \normalfont        \ifnum \c@secnumdepth >\m@ne            %\huge\bfseries \@chapapp\space \thechapter            \Huge\bfseries \thechapter.\space%            %\par\nobreak            %\vskip 20\p@        \fi        \interlinepenalty\@M        \Huge \bfseries #1\par\nobreak        \vskip 20\p@      }}    \makeatother % Removing the page number from parts in TOC + some spacing \titlecontents{part}[0em]{\vspace*{1.5em}\bfseries\Large}{}{}{}[\vspace*{0.5em}] % Changing spacing of the chapters in TOC (with dotted rule) % \titlecontents{chapter}[0em]{ %     \vspace*{0.2em}\bfseries}{}{}{\titlerule*[9.2pt]{.}\contentspage}[\vspace*{0.1em}] % Changing spacing of the chapters in TOC (without dotted rule) \titlecontents{chapter}[0em]{    \vspace*{0.2em}\bfseries}{}{}{\hfill\contentspage}[\vspace*{0.1em}] % Document information \author{} \title{\Huge{Parallel Computation of Sovereign Default Model}\\       \vspace{2pc}\large{a guide to efficient parallel computation in Julia}} \date{\the\year} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % BEGIN DOCUMENT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \begin{document}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Title page %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \maketitle  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Template foreword page (DELETE THIS) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \input{foreword(todelete)}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Initialization of TOCs, LOT, LOF & bibliographies %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Initialization of separate tables of contents for each part % because we want a different depth in each part of the main toc. \startcontents[tocpart1] % TOC only containing items from Part 1 \startcontents[tocpart2] % TOC only containing items from Part 2 \stopcontents[tocpart2] % Stopping and resuming in Part 2 \startcontents[tocappendix] % TOC only containing items from Appendix \stopcontents[tocappendix] % Stopping and resuming in Appendix % Initialization of separate bibliographies because we want % one bibliography for the first part and separate for each  % chapter of the second part. \newbibliography{preamble} \bibliographystyle{preamble}{plain} \newbibliography{ch1} \bibliographystyle{ch1}{plain} \newbibliography{ch2} \bibliographystyle{ch2}{plain} % Initialization of LOT (list of tables) and LOF (list of figures) \startlist[lotpart1]{lot} \startlist[lofpart1]{lof} % Macro by Lewis \newcommand{\lewis}[1]{{\color{blue} #1}}  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying Abstract & Keywords page %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \pagestyle{empty} \section*{Abstract} Solving default models is computationally expensive, thus requiring GPU to accelerate parallel computation. This note is inspired by prior results in solving the model in C++/CUDA with NVIDIA GPU. Use of high-level Julia programming removes many of the difficulties in prior result due to the nature of low-level programming. We significantly lower the cost of design of the model, and facilitate easy extension of the model. This leads to a sharp increase of programmer productivity and achieves performance on the same scale as official NVIDIA CUDA implementation. \section*{Keywords} Julia, CUDA, Sovereign Default, GPU, high-level language \clearpage  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying Acknowledgement page %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \pagestyle{empty} \section*{Acknowledgement}  % Signature \vspace{5em} \hfill \begin{minipage}[t][][t]{16em}%  \begin{center}%    \dotfill \\    Author's signature  \end{center}% \end{minipage}% \clearpage %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying main TOC (Table of Contents) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying merged tocpart1 and tocpart2 as one main TOC % Benefit of doing this is separate settings for each TOC \printcontents[tocpart1]{}{-1}[2]{\chapter*{Contents}}  \printcontents[tocpart2]{}{-1}[0]{} \printcontents[tocappendix]{}{-1}[0]{} \thispagestyle{empty}   % turn off page numbering for TOC %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying LOT (Lists of Tables) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \chapter*{List of Tables} \thispagestyle{empty}   % turn off page numbering for LOT \printlist[lotpart1]{lot}{}{}{} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Displaying LOF (List of Figures) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \chapter*{List of Figures} \thispagestyle{empty}   % turn off page numbering for LOF \printlist[lofpart1]{lof}{}{}{} \cleardoublepage\pagestyle{plain}   % turning on the page numbering %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % PART 1 PREAMBLE % In this part you can write an Introduction to your dissertation, % you can summarize all the publications which will be included % later on in full, and you can conclude your dissertation. %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % In this part, we want arabic numbering of chapters  \renewcommand\thechapter{\arabic{chapter}} \epigraphhead{} % Use before parts without epigraph \part*{Preamble} \addcontentsline{toc}{part}{Preamble} % Add starred part to contents     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART 1 - CHAPTER 1    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%        \chapter{Introduction}    Computation has become critical in economics. The upgrades of computation hardware had enabled economists to execute many complex nonlinear models that were previously just technically impossible to implement.        The development of GPU plays a central role in this revolution. CUDA in C is the standard platform in the industry for GPU coding due to its excellent performance on the NVIDIA GPUs. CUDA in C nonetheless contain inherent disadvantages. Based on low-level language C/C++, programming CUDA in C is an arduous, if not error-prone process. The trade-off is far from optimal for many researchers who desire to run complex programs, but also wish to save time and effort from the technicality of a low-level programming language for more important innovations.        Instead, we demonstrate Julia with CUDA as a simple and elegant replacement. We showcase the advantage through implementing sovereign default model with Julia CUDA. Highly nonlinear, Sovereign default models cannot be solved with fast methods like perturbation. The solution relies on alternative methods such as value function iteration, which are slow and suffers from the curse of dimensionality. Value iteration represents many characteristic features of economic computation: expensive iterations and frequent matrix storage and access. These disadvantages commonly seen across economic models makes efficient simulation of sovereign default model on a highly granulated input crucial and attractive. Many of the coding techniques are applicable to a wide range of quantitative economic models.      The choice of programming language and GPU compiler reflects our opinion and recommendation choosing Julia for GPU computation (another popular and highly recommended platform is Pytorch with Python). As the paper is written, CUDA in Julia is still under development with incomplete implementation compared to CUDA in C. We view this paper as a good opportunity to introduce CUDA in Julia. The high-level design of Julia language, and the highly Julia-style implementation of CUDA library in Julia facilitates the convenience to modify and upgrade a standard Julia program to its CUDA version.    In section 2, the noteworthy operations and syntax used in coding the model will be explained with examples (we assume some coding experience with common coding languages from the readers). Section 3 revisits the sovereign default model and the model's algorithm. Section 4 walks through the coding of model in Julia CUDA with emphasis on tools described in section 2. In the final section, we report the significant speed up in the benchmark results.      % This is an example text \cite{preamble}{example}.         % % QUOTE    % \begingroup    % \setlength{\epigraphwidth}{13.0cm}    % \renewcommand{\epigraphflush}{flushright}    % \vspace{0.3cm}    % \epigraph{\justifying\large\textit{"A thesis has to be presentable… but don't attach too much importance to it. If you do succeed in the sciences, you will do later on better things and then it will be of little moment. If you don’t succeed in the sciences, it doesn’t matter at all."}}{\textit{Paul Ehrenfest, 1985}}    % \vspace{0.3cm}    % \endgroup        % %\section{Some section}    % %\lipsum[1]    % %\subsection{Some subsection}    % %\lipsum[1]        % \begin{table}[ht]    %     \centering    %     \begin{tabular}{|c|c|}    %     \hline    %       Example col 1  &  Example col 2  \\    %       10             &  20             \\    %       \hline    %     \end{tabular}    %     \caption{Example table}    %     \label{tab:exampleTab}    % \end{table}        % \begin{figure}[ht]    %     \centering    %     \includegraphics[width=5cm]{example-grid-100x100pt}    %     % \includegraphics{}    %     \caption{Example figure}    %     \label{fig:exampleFig}    % \end{figure}        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART1 - CHAPTER 2    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \chapter{Operations and Syntax}    This section is dedicated to introduce the toolbox to implement the needed operations in Julia CUDA. The code snippets will demonstrate the use of the tools in the default model.     \section{Loop Fusion}    Loop fusion provides the convenient and Julia CUDA's linear algebra calculation, with speed on par to the well-known CUBLAS package for CUDA linear algebra operations. Instead of writing traditional vectorized loops, loop fusion provides a faster calculation without any overhead. The difference may be subtle in small scale calculations. However, when working with large arrays with big data, the overhead could be in the size of gigabytes, and execution will fail due to memory shortage. Loop fusion not only allow execution of the program, but may also cut execution time from hours down to seconds.\\    \\    A simple example of loop fusion with one matrix $X$ is shown below to evaluate $f(3*sqrt(X) + 4*x^3)$    \begin{lstlisting}    X .= f.(3.*sqrt.(X) + 4.*X.^3)    \end{lstlisting}    or equivalently    \begin{lstlisting}    @. X .= f(3*sqrt(X) + 4*X^3)    \end{lstlisting}    \\    Multiple vectorized operations, like \texttt{sqrt(X)} and \texttt{*}, are fused into a single loop without requiring extra space for temporary arrays.    Among the languages, Julia is unique in loop fusion. Other popular languages like Python or Matlab only allow a small sets of operations to be fused, but Julia allow generic application even for user-defined array types and functions. The convenient feature however requires careful inspection, and will be discussed in the default model implementation section.     \section{Mapreduce}        Mapreduce is a widely used method to process large data sets. Raised by Google in  "MapReduce: Simplified Data Processing on Large Clusters", by Jeffrey Dean and Sanjay Ghemawat, it relieves burden of programming details of parallelization and optimization in a simple interface. In Julia CUDA, \texttt{map} and \texttt{reduce} provide the high-order generic array operations. Highly extensible, Julia CUDA's map/reduce can be applied to all types of arrays, including the standard Julia CUDA array type, CuArray. Therefore, matrices stored in GPU are recommended to be handled by Mapreduce if applicable.\\        Operations \texttt{sum} and \texttt{max} are common in expected value calculation, and their implementation plays an important role in speeding up the algorithm.\\    [To be completed]\\    \\     \section{Kernels}    [To be completed]\\    Batch update of single loop\\    2D updates for multiple loop\\    designation of threads and blocks\\    Intermediate value allocation\\    Precision Setup\\    The design of kernels:\\     threadIdx, blockDim, blockIdx\\     The main difficulty in the default model is efficient calculation of expected values. Each random variable and conditional variable contributes to one extra loop in the calculation, as well as one extra dimension in the probability matrix. #explain the extra layer\\     We showcase different methods in expectation calculation, from high-level API to low-level kernels. We put special emphasis on the low level kernels. With Julia low-level style, the lines of code significantly decreases, and programming experience is improved by dynamic types and checked arithmetic [1]\\        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART1 - CHAPTER 3    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \chapter{Default Model}        We work on the standard sovereign default model (Arellano (2008)).$^1$ The model contains an open economy with a central government. For each period, the government choose between repaying the debt obligations or defaulting payment to maximize private utility, i.e., deciding by $V(y,b) = \max _{d\in\{0,1\}} (\delta V_d(y) + (1-\delta)V_r(y,b)).$\\    If satisfying the budget constraint     $$c+q(y,b')b' \leq y+b$$    the Value of Repayment is    $$V_r(y,b) = \max_{b'}U(c) + \beta \mathbf{E}V(y',b')$$    where $q(y,b')$ is price issued today given by last period debt $b'$ and exogenous endowment $y$.\\    The value function if defaulting is given by    $$ V_d(y) = U((1-\tau)y) + \mathbf{E}(\phi V(y',0) + (1-\phi)V_r(y')].$$    Where $\tau$ is the fraction cost lost in defaulting, and $\phi$ the exogenous probability to be readmitted to the financial markets next period. In our implementation, we follow Guerron's parametrization:\\    $U(c)=\frac{c^{1-\sigma}}{1-\sigma}$\\    $\beta = 0.953, \rho = 0.9, \sigma_y=0.025, \tau=0.15, \phi=0.28$\\    We use Tauchen Method to discretize the endowment process.\\                            \section{Algorithm}    The algorithm runs through each grid point of the state space grid of Endowment and Bonds ($\mathcal{Y} \times \mathcal{B}$). For each grid point, the values of default and repayment are sequentially calculated if there is a feasible spending plan given the budget. A decision is made for repayment or default for each grid point, and the value for the current priod is updated.\\    The pseudo-code is presented below$^{[1]}$:    [Input algorithm]             %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART1 - CHAPTER 4    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \chapter{Sovereign in Julia}        The section demonstrates the structure and key points in the coding the model. The algorithm is divided into three parts: Value of Default, Value of Repayment and Decision. The standard and CUDA implementation and compared side by side. The differences between standard Julia and CUDA in Julia are explained. It is noteworthy to highlight how subtle the differences are, showcasing the smoothness of transition from standard Julia coding to CUDA style programming in Julia. This smoothness of transition is a big plus to do Julia programming. Designs can be quickly implemented and tested in standard Julia, and tweaked to large scale GPU computation efficiently.            \section{Value of Default}    [phi is missing in texttt format]\\     Reduce operation: In the default model, the expected value calculation is handled by $\mathbf{E}[f(y)|iy] = \sum_{\texttt{possible values of y}} f(y)*P(y|iy)$. For a matrix of $\mathbf{E}[f(y)|iy]$ on the grid $(y,iy)$, one common implementation is to run through a double for-loop:    \begin{lstlisting}    sum_default = CUDA.zeros(Ny)     # Ny is the size of grid points of possible values of y    for y in 1:Ny        for iy in 1:Ny            sumdefault[y] += f(y)*P[y,iy]        end    end    \end{lstlisting}    Instead, store $f(y|iy)$ for each $(y,iy)$ in the matrix and reduce along the columns. The benefit of initializing temporary matrix will be discussed in section 4.3.     \begin{lstlisting}    temp_vd = CUDA.zeros(Ny,Ny) #Initialize    for y in 1:Ny        for iy in 1:Ny            temp_vd[y,iy] = f(y))*P[y,iy]        end    end    sum_default = reduce(+, temp_vd, dims=2)    \end{lstlisting}    \\    \\    Loop fusion: Given the value function $$f(y) = \phi V(y',0) + (1-\phi)V_d(y')|y(i_y))$$ An alternative method is linear algebra with loop fusion. Loop fusion provides a significant speed up just by adding a few dots to the operation to fuse Julia's primitive operations. \lewis{, i.e., using Julia's primitive operations}:    The following snippet is equivalent to $f(y)$    \begin{lstlisting}    ϕ.*V[y',0] .+ (1-ϕ).*V_d[y',i_y]    \end{lstlisting}    And we can summarize the Value of default calculation in two lines:    \begin{lstlisting}    temp = β* P .* CUDA.transpose(ϕ.*V[y',0] .+    \end{lstlisting}    \begin{lstlisting}           (1-ϕ).*V_d[y',i_y])    \end{lstlisting}    \begin{lstlisting}    Vd .= sumdef .+ reduce(+, temp, dims=2)    \end{lstlisting}    Under careful design, we also can split the operations into individual components to provide further speed up for the same operation:    \begin{lstlisting}    A .= ϕ* V0[:,1]    A .+= (1-ϕ)* Vd0    A.= ϕ.* V0[:,1] .+ (1-ϕ).* Vd0    temp = P    temp .*= CUDA.transpose(A)    temp .*= β    \end{lstlisting}         \section{Value of Repayment}        Value of repayment consumes the largest bulk of computation power and should be the first priority of optimization. The expensive computation cost comes from an expected value calculation consisting of four variables, reaching computation complexity to approximatly $O(n^4)$. Our design builds on Guerron's implementation with Thrust in C CUDA.\\    In our CPU version, Julia-style linear algebra and loop fusion operations again replace the standardized for-loops. In the CUDA implementation, division of kernels provides simple and efficient computation by reducing synchronizing cost and temporary matrix allocation, two banes common to large-scale economic model simulations.\\        In the CPU design, Julia's \texttt{'} operator reduces one extra for-loop, speeding up the calculation.\\        \begin{lstlisting}    for b in 1:Nb            c = exp(Y[iy]) + B[ib] - Price0[iy,b]*B[b]             if c > 0                #A reduction of a for-loop with the ' operator                sumret = P[iy,:]'V0[:,b]                vr = U(c) + β * sumret                Max = max(Max, vr)            end        end    \end{lstlisting}\\        In Guerron's CUDA implementation, the Thrust code using operator provides an efficient and intuitive transition of CPU code to GPU code. This paper improves upon the design. First we inspect the implicit extra computation cost in the Thrust design: large variation of execution time among the threads may impact overall performance. During every round of computation in the threads, the quicker threads will wait for the slower threads to finish calculation, requiring additional synchronization time for each round of computation. In addition, ssame data will be calculated, and freshly stored on device for each thread, requiring additional device space and computation power. \\        A simple and efficient fix is to divide the value repayment calculation into components. Each component is computed in a small kernel, thus the waiting time is reduced in synchronization. The code for the three kernels are attached in the appendix and GitHub.\\         Since the \texttt{'} operator is not currently supported in CUDA kernel, the calculation of sum of return requires one additional for-loop, a total of four for-loops. Two for-loops are reduced by the two-dimensional thread assignment, and two loops are contained in kernel calculations. This reduces the complexity from $O(n^4)$ to roughly $O(n^2)$, a big speed up to about twenty-five hundred times faster even on a rough $50\times50$ grid (the maximum speed up is bounded by the GPU design). In the bench-marking section, the two-for-loop design will be shown to yield satisfying result.\\        \section{Coding advice}    While powerful, CUDA in Julia is still a relatively young platform, and this section aims to point out some pitfalls to avoid based on the model's implementation.\\        1. Splitting Loop Fusion in smaller sections may improve performance if no extra memory is allocated.     The dots in loop fusion are essentially broadcast operations. The greatest improvement of loop fusion comes by avoiding allocating and de-allocating temporary arrays should each broadcast be executed sequentially. However, automatically fusing multiple broadcast operations does not show the level of improvement as expected. The speed up of loop fusion diminishes when too many loops are fused together.        Instead, dividing the fusion back to individual broadcast operations may offer better performance if the code is designed to allocate minimal extra space to store temporary results.    For example, consider the following snippet to calculate $\text{temp} = \beta * P * (A)^T$ :    \begin{lstlisting}    temp = P    temp .*= CUDA.transpose(A)    temp .*= β    \end{lstlisting}    is much faster than    \begin{lstlisting}    temp = β* P .* CUDA.transpose(A)    \end{lstlisting}    in Julia and no extra array is allocated.        In practice, we recommend splitting the operation as above for best performance.\\        2. Allocating temporary matrix during initialization    An optional trade-off is to increase speed at the cost of extra memory allocation. For instance, in Value of Repayment, Cost, $C[iy,ib,b]$, is a temporary matrix containing three variables. Allocating the cost matrix beforehand on the device/GPU removes dynamic allocation of memory for cost in each kernel. The freshly calculated cost will be assigned to the pre-allocated matrix. Efficient linear algebra operations could consequently be performed on the matrix, offering a speed-up compared to the standard vectorized for-loops. The performance of the trade-off and the limits will be described in the Benchmark section.\\     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART1 - CHAPTER 5    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \chapter{Benchmarking}     \section{Julia CUDA}    The Benchmark is performed on the three main components of the computation: value of default, value of repayment and decision. The X-axis shows the size of Gridpoints for the Endowment$\times$Bond Matrix of size $Ny*Nb$, and Y-axis shows the median running time of each component.    \begin{figure}[h]        \centering        \includegraphics[width=15cm]{BenchmarkGPU1.png}        % \includegraphics{}        \caption{GPU Benchmark of sovereign default model}        \label{fig:exampleFig}    \end{figure}\\    The figure showcase the performance under granulation up to a $500\times500$ grid space for the Endowment$\times$Bond matrix. The increase in running time does not show a polynomial factor and fits more to a linear growth. This indicates the GPU processor has not reached its physical limit even with a large grid. The speed is extremely efficient and the grid size is already at $250000$ points.\\    The major cost comes from the memory usage. For example, to store a single Cost Matrix with 500 grid points requires $500^3$ of Float32 memory, equivalent to $500^3*32/10^9 =4$GB of RAM. At $800$ grid points, the required RAM memory reaches $16$ GB. Further granulation would be uneconomical and even unrealistic on a personal computer.\\In conclusion, the program can run extremely efficiently under reasonable and desirable granulation of the variables, but is restricted by hardware storage.\\    A quick fix of the memory issue is to remove the high-dimensional matrix that had speed up the calculation. We include the fixed Julia code in the GitHub page. In the trade-off of memory for speed, the standard vectorized loops replaces the Mapreduce and linear algebra operations on high-dimensional matrices. The effect of the trade-off of is presented in the following Benchmark:    \\    \\    \section{Comparison: Julia CUDA vs Standard Julia \lewis{(CPU)}}    The comparison of the CPU Benchmark to the GPU benchmark showcases the advantage and necessity to switch to GPU computation:        \begin{figure}[h]        \centering        \includegraphics[width=15cm]{CPUvGPU.png}        % \includegraphics{}        \caption{Comparison of the three components in the model, GPU vs CPU}        \label{fig:exampleFig}    \end{figure}\\        The program's running time is dominated by the most time-consuming process, Value of Repayment calculation. The Value of Repayment calculation has complexity of $O(Ny^2Nb^2)=O(n^4)$ for Endowment$\times$Bond matrix of size $n\times n$. Run time for value of repayment calculation grows in polynomial scale to over 7 seconds on a $150\times 150$ size grid. Suppose the algorithm takes 500 iterations, then calculating value of repayment alone takes almost an hour. Meanwhile Julia CUDA completes the same task in $0.000767\mu s*500=0.35$ seconds. % Bibliography \bibliography{preamble}{ms}{Bibliography} \addcontentsline{toc}{chapter}{Bibliography} % Add starred chapter to contents % Closing the tocs and lists \stopcontents[tocpart1] % Stops the tocpart1 \stoplist[lotpart1]{lot} % Stops the lotpart1 \stoplist[lofpart1]{lof} % Stops the lofpart1  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % GROUP FOR PART 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \begingroup % In this group, we want Bibliographies to show up as sections \patchcmd{\thebibliography}{\chapter*}{\section*}{}{}  % In this group, we want Roman numbering of chapters  \renewcommand\thechapter{\Roman{chapter}} % In this group, we want to restart the chapter numbering \setcounter{chapter}{-1}\stepcounter{chapter} % Resume the contents counter of tocpart2 to include items from PART 2 \resumecontents[tocpart2] %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % PART 2 PUBLICATIONS % In this part you can include all your publications which % the dissertation should comprise of. Depending on your uni % guidelines, the publications could be attached in their original % templates (just as pdfs), or they can be put into a unified % style of this dissertation. Adding them as pdfs is for sure % easier, but it degrades the style of the document and it % also can introduce problems with copyright (check the guidelines % of the publishers where your papers were printed). %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \cleardoublepage \epigraphhead[400]{\smalltoc{p2}{0}{0}{}} \part*{Publications}\label{Publications} \addcontentsline{toc}{part}{Publications}     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART2 - CHAPTER 1    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % \chapter{Title of the First Publication}    \chapter[Shortened Title of the First Publication \dots]            {Very Long Title of the First Publication}        % Mini table of content for this chapter {name}{start}{depth}{section name}    \smalltoc{p2ch1}{0}{3}{Outline}        \section*{Bibliographic Information}    % The package biblatex which supports \fullcite collides with the package multibbl    % I have not found a solution how to print a bib item in the text so I write it out.    % If you find a solution, please, post it here: https://tex.stackexchange.com/questions/173935    Doe,~J., Coffee,~T., Zinn,~C., Leleux,~E., Corcoran,~B., (2019, July). Example research topic in example spaces. In 2019 international example conference (IEC) (pp.1-5). Publisher. \href{https://doi.org}{xxxx.xxxx.xxxxxxx}. \href{https://arxiv.org}{arXiv:xxxx.xxxxx}.        \section*{Author's contribution}    The author contributed to \dots. Furthermore, wrote a significant part of \dots.        \section*{Copyright Notice}    \copyright \the\year\ Publisher. This is an accepted version of this article published in \href{https://doi.org}{doi-xx-xxxx}. Clarification of the copyright adjusted according to the guidelines of the publisher.    \clearpage        % Include the contents of the publication here    \include{publication1/publication1}        % Bibliography    \phantomsection    \addcontentsline{toc}{section}{Bibliography}    \bibliography{ch1}{publication1/publication1}{Bibliography}        \stopcontents[p2ch1]        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    % PART 2 - CHAPTER 2    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    \chapter{Title of the Second Publication}        % Mini table of content for this chapter {name}{start}{depth}{section name}    \smalltoc{p2ch2}{0}{3}{Outline}        \section*{Bibliographic Information}    % The package biblatex which supports \fullcite collides with the package multibbl    % I have not found a solution how to print a bib item in the text so I write it out.    % If you find a solution, please, post it here: https://tex.stackexchange.com/questions/173935    Doe,~J., Coffee,~T., Zinn,~C., Leleux,~E., Corcoran,~B., (2019, July). Example research topic in example spaces. In 2019 international example conference (IEC) (pp.1-5). Publisher. \href{https://doi.org}{xxxx.xxxx.xxxxxxx}. \href{https://arxiv.org}{arXiv:xxxx.xxxxx}.        \section*{Author's contribution}    The author contributed to \dots. Furthermore, wrote a significant part of \dots.        \section*{Copyright Notice}    \copyright \the\year\ Publisher. This is an accepted version of this article published in \href{https://doi.org}{doi-xx-xxxx}. Clarification of the copyright adjusted according to the guidelines of the publisher.    \clearpage        % Include the contents of the publication here    \include{publication2/publication2}        % Bibliography    \phantomsection    \addcontentsline{toc}{section}{Bibliography}    \bibliography{ch2}{publication2/publication2}{Bibliography}        \stopcontents[p2]    \stopcontents[p2ch2]    \stopcontents[tocpart2]    \endgroup %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % APPENDIX (in case you need one) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Resume the contents counter of tocpart2 to include items from PART 2 \resumecontents[tocappendix] \appendix \cleardoublepage \epigraphhead[400]{    \hrule\vspace{1pc}    \printcontents[tocappendix]{}{0}[0]{}    \vspace{1pc}\hrule} \part*{Appendix} \addcontentsline{toc}{part}{Appendix} % Add starred part to contents %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % APPENDIX - CHAPTER 1 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \chapter{First Appendix} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % APPENDIX - CHAPTER 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \chapter{Second Appendix} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % APPENDIX - CHAPTER 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \chapter*{Complete List of Publications} \addcontentsline{toc}{chapter}{Complete list of publications} % Add starred part to contents %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % APPENDIX - CV %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \clearpage \phantomsection \addcontentsline{toc}{chapter}{Curriculum Vit\ae} % Add starred part to contents \include{cv} \stopcontents[tocappendix] \end{document}